# 获取数据

赛事组织方只提供了所有图片的地址，而没有把图片打包提供给我们下载，这样就需要写个小爬虫，从这些地址中爬取图片。

需要爬取的数据量很大，据说有30G大小，而且部分图片还在长城之外，所以第一步下载图片就是个麻烦活，可以说在国内很难靠自己获取到全部数据集。

所以项目后面如果出现了图片缺失的话，我们只能分析分析图片的url字符中包含了什么信息，也许能弥补一点正确率。

## 1. 处理json文件

将json格式的数据转换为dataframe格式的数据，在下载和建模过程中，dataframe格式的数据遍历起来会方便很多。


## 2. 下载

因为数据量大，几乎不可能一次性下完，所以要考虑断点下载，即下载之前检查该图片是否已经存在于文件夹中，如果存在则跳过，不存在则下载。


