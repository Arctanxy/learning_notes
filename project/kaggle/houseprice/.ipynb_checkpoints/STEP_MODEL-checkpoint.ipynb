{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GET DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1460 entries, 0 to 1459\n",
      "Data columns (total 81 columns):\n",
      "Id               1460 non-null int64\n",
      "MSSubClass       1460 non-null int64\n",
      "MSZoning         1460 non-null object\n",
      "LotFrontage      1201 non-null float64\n",
      "LotArea          1460 non-null int64\n",
      "Street           1460 non-null object\n",
      "Alley            91 non-null object\n",
      "LotShape         1460 non-null object\n",
      "LandContour      1460 non-null object\n",
      "Utilities        1460 non-null object\n",
      "LotConfig        1460 non-null object\n",
      "LandSlope        1460 non-null object\n",
      "Neighborhood     1460 non-null object\n",
      "Condition1       1460 non-null object\n",
      "Condition2       1460 non-null object\n",
      "BldgType         1460 non-null object\n",
      "HouseStyle       1460 non-null object\n",
      "OverallQual      1460 non-null int64\n",
      "OverallCond      1460 non-null int64\n",
      "YearBuilt        1460 non-null int64\n",
      "YearRemodAdd     1460 non-null int64\n",
      "RoofStyle        1460 non-null object\n",
      "RoofMatl         1460 non-null object\n",
      "Exterior1st      1460 non-null object\n",
      "Exterior2nd      1460 non-null object\n",
      "MasVnrType       1452 non-null object\n",
      "MasVnrArea       1452 non-null float64\n",
      "ExterQual        1460 non-null int64\n",
      "ExterCond        1460 non-null int64\n",
      "Foundation       1460 non-null object\n",
      "BsmtQual         1423 non-null float64\n",
      "BsmtCond         1423 non-null float64\n",
      "BsmtExposure     1422 non-null object\n",
      "BsmtFinType1     1423 non-null object\n",
      "BsmtFinSF1       1460 non-null int64\n",
      "BsmtFinType2     1422 non-null object\n",
      "BsmtFinSF2       1460 non-null int64\n",
      "BsmtUnfSF        1460 non-null int64\n",
      "TotalBsmtSF      1460 non-null int64\n",
      "Heating          1460 non-null object\n",
      "HeatingQC        1460 non-null int64\n",
      "CentralAir       1460 non-null object\n",
      "Electrical       1459 non-null object\n",
      "1stFlrSF         1460 non-null int64\n",
      "2ndFlrSF         1460 non-null int64\n",
      "LowQualFinSF     1460 non-null int64\n",
      "GrLivArea        1460 non-null int64\n",
      "BsmtFullBath     1460 non-null int64\n",
      "BsmtHalfBath     1460 non-null int64\n",
      "FullBath         1460 non-null int64\n",
      "HalfBath         1460 non-null int64\n",
      "BedroomAbvGr     1460 non-null int64\n",
      "KitchenAbvGr     1460 non-null int64\n",
      "KitchenQual      1460 non-null int64\n",
      "TotRmsAbvGrd     1460 non-null int64\n",
      "Functional       1460 non-null object\n",
      "Fireplaces       1460 non-null int64\n",
      "FireplaceQu      770 non-null float64\n",
      "GarageType       1379 non-null object\n",
      "GarageYrBlt      1379 non-null float64\n",
      "GarageFinish     1379 non-null object\n",
      "GarageCars       1460 non-null int64\n",
      "GarageArea       1460 non-null int64\n",
      "GarageQual       1379 non-null float64\n",
      "GarageCond       1379 non-null float64\n",
      "PavedDrive       1460 non-null object\n",
      "WoodDeckSF       1460 non-null int64\n",
      "OpenPorchSF      1460 non-null int64\n",
      "EnclosedPorch    1460 non-null int64\n",
      "3SsnPorch        1460 non-null int64\n",
      "ScreenPorch      1460 non-null int64\n",
      "PoolArea         1460 non-null int64\n",
      "PoolQC           7 non-null float64\n",
      "Fence            281 non-null object\n",
      "MiscFeature      54 non-null object\n",
      "MiscVal          1460 non-null int64\n",
      "MoSold           1460 non-null int64\n",
      "YrSold           1460 non-null int64\n",
      "SaleType         1460 non-null object\n",
      "SaleCondition    1460 non-null object\n",
      "SalePrice        1460 non-null int64\n",
      "dtypes: float64(9), int64(39), object(33)\n",
      "memory usage: 924.0+ KB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import warnings\n",
    "from tqdm import tqdm # 进度条工具\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline \n",
    "\n",
    "PATH = 'H:/learning_notes/project/kaggle/houseprice/data/'\n",
    "# PATH = 'C:/Users/Dl/Documents/GitHub/learning_notes/project/kaggle/houseprice/data/'\n",
    "train_data = pd.read_csv(PATH + 'train.csv')\n",
    "train_data = train_data.replace({\n",
    "    'Ex':5,\n",
    "    'Gd':4,\n",
    "    'TA':3,\n",
    "    'Fa':2,\n",
    "    'Po':1\n",
    "})\n",
    "train_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kaggle 分享的note基本都是对这些特征进行流水线式的处理，我之前也按他们的思路尝试过，思路大致如下：\n",
    "\n",
    "填充缺失值 >>> 处理数值型特征（StandarScaler & np.log） >>> 处理类目型（pd.get_dummies)特征 >>> 建模（Lasso,KernelRidge,xgboost） >>> 验证（按月份划分测试与训练集用于本地验证） >>> 调参（GridSearchCV & RandomizedSearchCV） >>> 多模型融合（Voting & Blend）\n",
    "\n",
    "最终得分停留在12.105，感觉这种处理方式很不好，做完了之后都想不起来自己干了个啥，所以我准备在这里将所有特征分文别类地建立一个属于自己的模型。\n",
    "\n",
    "> 注：为了便于阐述建模思路，本Notebook不包含各类数据对价格的影响图表"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 区位因素\n",
    "\n",
    "区位因素有：MSZoning;MSSubClass;Neighborhood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1460 entries, 0 to 1459\n",
      "Data columns (total 3 columns):\n",
      "MSSubClass      1460 non-null int64\n",
      "MSZoning        1460 non-null object\n",
      "Neighborhood    1460 non-null object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 34.3+ KB\n"
     ]
    }
   ],
   "source": [
    "region_features = train_data[['MSSubClass','MSZoning','Neighborhood']]\n",
    "y = np.log(train_data['SalePrice']/train_data['GrLivArea']) # 单价\n",
    "region_features.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.18121917586\n"
     ]
    }
   ],
   "source": [
    "region_features = region_features.astype(str) # 这三项都作为类目型特征进行处理\n",
    "x = pd.get_dummies(region_features)\n",
    "clf = RidgeCV(alphas=[1e-5,1e-4,1e-3,1e-2,1e-1])\n",
    "clf.fit(x,y)\n",
    "yp = clf.predict(x)\n",
    "print(np.sqrt(mean_squared_error(yp,y)))\n",
    "# x.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "效果惊人，这个八成过拟合了，这样验证效果是不合理的，应该将数据分为训练集和测试集，使用训练集训练模型，然后使用测试集检验效果。\n",
    "\n",
    "最常见又简单的做法是使用sklearn.cross_validation.train_test_split()函数进行分割："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19154207526\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.15,random_state=10) # 测试集大小随您喜欢，不过为了保证模型效果，训练集需要有足够的数据量\n",
    "clf = RidgeCV(alphas=[1e-5,1e-4,1e-3,1e-2,1e-1]) # 重新定义模型，要不然就会直接使用上面已经建立好的模型了\n",
    "clf.fit(x_train,y_train)\n",
    "yp = clf.predict(x_test)\n",
    "print(np.sqrt(mean_squared_error(yp,y_test))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上述代码中，数据划分是随机的，因为这种随机性导致随着划分方式的不同会有不同的测试结果，需要多测几次求平均值，正好sklearn中还提供了一个更加方便的交叉验证函数:cross_val_score()，它会使用KFold方法将数据集划分我N个部分，然后用其中N-1个子集合并作为训练集，剩下的一个子集作为测试集，我们可以直接用这个函数来验证每一步的效果："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('得分:19.2605', '特征数量:45')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def check_data(x,y,cv=10):\n",
    "    # clf =  RidgeCV(alphas=[1e-5,1e-4,1e-3,1e-2,1e-1])\n",
    "    clf = KernelRidge(kernel='linear')\n",
    "    scores = cross_val_score(clf,x,y,scoring='neg_mean_squared_error',cv = cv) # 返回的是负数\n",
    "    scores = [np.sqrt((-1)*score) for score in scores]\n",
    "    return np.mean(scores)\n",
    "'得分:%.4f' % (100 * check_data(x,y)),'特征数量:%d' % len(x.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 年代因素"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "年代因素有：YearBuilt;YearRemodAdd;YrSold;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1460 entries, 0 to 1459\n",
      "Data columns (total 4 columns):\n",
      "YearBuilt       1460 non-null int64\n",
      "YearRemodAdd    1460 non-null int64\n",
      "YrSold          1460 non-null int64\n",
      "MoSold          1460 non-null int64\n",
      "dtypes: int64(4)\n",
      "memory usage: 45.7 KB\n"
     ]
    }
   ],
   "source": [
    "year_features = train_data[['YearBuilt','YearRemodAdd','YrSold','MoSold']] # 不同月份之间房价差异要大过不同年份，所以月份也是很重要的因素\n",
    "year_features.info() # 查漏补缺"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**捣鼓新特征**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    764\n",
       "1    696\n",
       "Name: Remodeled, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "year_features['Remodeled'] = (train_data['YearBuilt'] != train_data['YearRemodAdd']) * 1\n",
    "year_features['Remodeled'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2      100\n",
       "1       64\n",
       "5       41\n",
       "3       39\n",
       "4       36\n",
       "32      31\n",
       "6       30\n",
       "7       30\n",
       "9       25\n",
       "38      25\n",
       "40      24\n",
       "8       24\n",
       "52      24\n",
       "10      23\n",
       "48      23\n",
       "33      23\n",
       "11      22\n",
       "43      22\n",
       "12      22\n",
       "50      21\n",
       "54      20\n",
       "16      20\n",
       "37      20\n",
       "31      19\n",
       "44      19\n",
       "49      18\n",
       "42      17\n",
       "46      17\n",
       "55      17\n",
       "39      16\n",
       "      ... \n",
       "72       3\n",
       "73       3\n",
       "75       3\n",
       "24       3\n",
       "107      3\n",
       "96       3\n",
       "101      3\n",
       "76       2\n",
       "65       2\n",
       "128      2\n",
       "118      2\n",
       "111      2\n",
       "64       2\n",
       "105      1\n",
       "130      1\n",
       "129      1\n",
       "104      1\n",
       "127      1\n",
       "126      1\n",
       "123      1\n",
       "120      1\n",
       "103      1\n",
       "116      1\n",
       "115      1\n",
       "112      1\n",
       "80       1\n",
       "110      1\n",
       "136      1\n",
       "108      1\n",
       "137      1\n",
       "Name: Age, Length: 122, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "year_features['Age'] = train_data['YrSold'] - train_data['YearBuilt'] + 1\n",
    "year_features['Age'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "竟然有一百多年的房子在卖！！！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "year_features['YrSold'] = year_features['YrSold'].astype(str)\n",
    "year_features['MoSold'] = year_features['MoSold'].astype(str)\n",
    "year_features = pd.get_dummies(year_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('得分:18.0132', '特征数量:66')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = pd.concat([x,year_features],axis=1)\n",
    "'得分:%.4f' % (100*check_data(x,y)),'特征数量:%d' % len(x.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 销售方式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "不同的销售方式也会影响到价格，比如期房和现房价格不同，卖给亲戚和卖给陌生人价格也会有不同。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sale_features = train_data[['SaleType','SaleCondition']].astype(str) #这里其实本来就是str类型，但是还是加一下astype，免得出幺蛾子\n",
    "sale_features = pd.get_dummies(sale_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('得分:18.0915', '特征数量:81')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = pd.concat([x,sale_features],axis=1)\n",
    "'得分:%.4f' % (100*check_data(x,y)),'特征数量:%d' % len(x.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "模型效果并没有得到改善"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 交通地形因素"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1460 entries, 0 to 1459\n",
      "Data columns (total 7 columns):\n",
      "LotFrontage    1460 non-null float64\n",
      "Street         1460 non-null object\n",
      "Alley          1460 non-null object\n",
      "LandContour    1460 non-null object\n",
      "LandSlope      1460 non-null object\n",
      "Condition1     1460 non-null object\n",
      "Condition2     1460 non-null object\n",
      "dtypes: float64(1), object(6)\n",
      "memory usage: 79.9+ KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('得分:18.1439', '特征数量:110')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traffic_landform = train_data[['LotFrontage','Street','Alley','LandContour','LandSlope','Condition1','Condition2']]\n",
    "for f in ['LotFrontage','Street','Alley','LandContour','LandSlope','Condition1','Condition2']:\n",
    "    traffic_landform[f] = traffic_landform[f].fillna(traffic_landform[f].mode()[0])\n",
    "print(traffic_landform.info())\n",
    "traffic_landform['LotFrontage'] = traffic_landform['LotFrontage'].fillna(traffic_landform['LotFrontage'].mean())\n",
    "traffic_landform = pd.get_dummies(traffic_landform)\n",
    "x = pd.concat([x,traffic_landform],axis=1)\n",
    "'得分:%.4f' % (100*check_data(x,y)),'特征数量:%d' % len(x.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 房屋总体特征\n",
    "\n",
    "从外面一眼能看见的特征，买房子第一印象很重要"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('得分:14.4589', '特征数量:199')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "property_feature = train_data[['LotArea','LotShape','Utilities','LotConfig','BldgType','HouseStyle','OverallQual',\n",
    "                               'OverallCond','RoofStyle','RoofMatl','Exterior1st','Exterior2nd','MasVnrType',\n",
    "                              'MasVnrArea','ExterQual','ExterCond','1stFlrSF','2ndFlrSF','GrLivArea','Functional']]\n",
    "property_feature['MasVnrType'] = property_feature['MasVnrType'].fillna(property_feature['MasVnrType'].mode()[0])\n",
    "property_feature['MasVnrArea'] = property_feature['MasVnrArea'].fillna(property_feature['MasVnrArea'].median())\n",
    "property_feature = pd.get_dummies(property_feature)\n",
    "x = pd.concat([x,property_feature],axis=1)\n",
    "'得分:%.4f' % (100*check_data(x,y)),'特征数量:%d' % len(x.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 房屋内部配置"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data_description.txt 中所描述的'Bedroom'和'Kitchen'两个字段并未出现在训练集中，我们中国人最关心的卧室数量，在这个数据集里面竟然丢失了！？？看看美国人买房子的时候都关心啥：地下室？？车库？？游泳池？？门廊？？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1460 entries, 0 to 1459\n",
      "Data columns (total 41 columns):\n",
      "Foundation       1460 non-null object\n",
      "BsmtQual         1460 non-null float64\n",
      "BsmtCond         1460 non-null float64\n",
      "BsmtExposure     1460 non-null object\n",
      "BsmtFinType1     1460 non-null object\n",
      "BsmtFinSF1       1460 non-null int64\n",
      "BsmtFinType2     1460 non-null object\n",
      "BsmtFinSF2       1460 non-null int64\n",
      "BsmtUnfSF        1460 non-null int64\n",
      "TotalBsmtSF      1460 non-null int64\n",
      "Heating          1460 non-null object\n",
      "HeatingQC        1460 non-null int64\n",
      "CentralAir       1460 non-null object\n",
      "Electrical       1460 non-null object\n",
      "LowQualFinSF     1460 non-null int64\n",
      "BsmtFullBath     1460 non-null int64\n",
      "BsmtHalfBath     1460 non-null int64\n",
      "FullBath         1460 non-null int64\n",
      "HalfBath         1460 non-null int64\n",
      "KitchenQual      1460 non-null int64\n",
      "TotRmsAbvGrd     1460 non-null int64\n",
      "Fireplaces       1460 non-null int64\n",
      "FireplaceQu      1460 non-null float64\n",
      "GarageType       1460 non-null object\n",
      "GarageYrBlt      1460 non-null object\n",
      "GarageFinish     1460 non-null object\n",
      "GarageCars       1460 non-null int64\n",
      "GarageArea       1460 non-null int64\n",
      "GarageQual       1460 non-null float64\n",
      "GarageCond       1460 non-null float64\n",
      "PavedDrive       1460 non-null object\n",
      "WoodDeckSF       1460 non-null int64\n",
      "OpenPorchSF      1460 non-null int64\n",
      "EnclosedPorch    1460 non-null int64\n",
      "3SsnPorch        1460 non-null int64\n",
      "ScreenPorch      1460 non-null int64\n",
      "PoolArea         1460 non-null int64\n",
      "PoolQC           1460 non-null float64\n",
      "Fence            1460 non-null object\n",
      "MiscFeature      1460 non-null object\n",
      "MiscVal          1460 non-null int64\n",
      "dtypes: float64(6), int64(22), object(13)\n",
      "memory usage: 467.7+ KB\n"
     ]
    }
   ],
   "source": [
    "inner_feature = train_data[['Foundation','BsmtQual','BsmtCond','BsmtExposure','BsmtFinType1','BsmtFinSF1','BsmtFinType2',\n",
    "                           'BsmtFinSF2','BsmtUnfSF','TotalBsmtSF','Heating','HeatingQC','CentralAir','Electrical',\n",
    "                           'LowQualFinSF','BsmtFullBath','BsmtHalfBath','FullBath','HalfBath',\n",
    "                           'KitchenQual','TotRmsAbvGrd','Fireplaces','FireplaceQu','GarageType','GarageYrBlt',\n",
    "                           'GarageFinish','GarageCars','GarageArea','GarageQual','GarageCond','PavedDrive','WoodDeckSF',\n",
    "                           'OpenPorchSF','EnclosedPorch','3SsnPorch','ScreenPorch','PoolArea','PoolQC','Fence','MiscFeature',\n",
    "                           'MiscVal']]\n",
    "# 很多数据有缺失，为了避免曲解数据含义，要一个一个填充\n",
    "inner_feature[['BsmtQual','BsmtCond']] = inner_feature[['BsmtQual','BsmtCond']].fillna(0) # NAN 代表没有地下室，那么地下室质量可以置为最低级：0\n",
    "inner_feature[['BsmtExposure','BsmtFinType1','BsmtFinType2']] = inner_feature[['BsmtExposure','BsmtFinType1','BsmtFinType2']].fillna('None')\n",
    "inner_feature['Electrical'] = inner_feature['Electrical'].fillna(inner_feature['Electrical'].mode()[0])\n",
    "inner_feature['FireplaceQu'] = inner_feature['FireplaceQu'].fillna(0.0)\n",
    "inner_feature['GarageType'] = inner_feature['GarageType'].fillna('None')\n",
    "inner_feature['GarageYrBlt'] = inner_feature['GarageYrBlt'].astype(str) # 年份，转化为str\n",
    "inner_feature['GarageYrBlt'] = inner_feature['GarageYrBlt'].fillna('None')\n",
    "inner_feature['GarageFinish'] = inner_feature['GarageFinish'].fillna('None')\n",
    "inner_feature['GarageQual'] = inner_feature['GarageQual'].fillna(0)\n",
    "inner_feature['GarageCond'] = inner_feature['GarageCond'].fillna(0)\n",
    "inner_feature['PoolQC'] = inner_feature['PoolQC'].fillna(0)\n",
    "inner_feature['Fence'] = inner_feature['Fence'].fillna('None')\n",
    "inner_feature['MiscFeature'] = inner_feature['MiscFeature'].fillna('None')\n",
    "inner_feature.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('得分:13.6306', '特征数量:387')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inner_feature = pd.get_dummies(inner_feature)\n",
    "x = pd.concat([x,inner_feature],axis=1)\n",
    "'得分:%.4f' % (100*check_data(x,y)),'特征数量:%d' % len(x.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 逐步向后CV\n",
    "\n",
    "逐步地一个一个添加变量，如果新添加了特征之后模型得分得到改善则保留这个特征，否则去掉这个特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████| 386/386 [03:32<00:00,  1.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1460 entries, 0 to 1459\n",
      "Columns: 130 entries, GrLivArea to MiscFeature_Othr\n",
      "dtypes: float64(2), int64(19), uint8(109)\n",
      "memory usage: 395.0 KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, 0.122636915562137)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_new = pd.DataFrame()\n",
    "first_feature = x.GrLivArea.values # 选一个很重要，肯定会包含在最终模型中的特征，我这里选择的是GrLivArea，也就是生活面积\n",
    "x_new['GrLivArea'] = first_feature\n",
    "x = x.drop('GrLivArea',axis=1)\n",
    "cols = x.columns\n",
    "init_score = check_data(x_new,y,cv=10) # 如果你用的电脑比较慢的话，可以把CV数量调低一点\n",
    "for col in tqdm(cols):\n",
    "    x_new[col] = x[col]\n",
    "    new_score = check_data(x_new,y,cv=5)\n",
    "    if new_score <= init_score:\n",
    "        init_score = new_score # 添加特征并更新得分\n",
    "        continue\n",
    "    else:\n",
    "        x_new = x_new.drop(col,axis=1) # 去除特征\n",
    "x_new.info(),init_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最终选择了130个特征，得分12.2637,离理想的分数还有较大的差距。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomizedSearchCV & GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "特征工程之后我们要选择几个模型进行调参，为后面的模型融合做准备，这里选择RandomizedSearchCV或者GridSearchCV都可以，我之前用的都是GridSearchCV，所以这里要尝试一下RandomizedSearchCV的效果，随机也许能出奇迹。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "初步选择的模型有KernelRidge,RandomForest,xgboost,SVR,GradientBoostingRegressor,Lasso六个模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KernelRidge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('best parameters:',\n",
       " {'alpha': 0.42270389949504661,\n",
       "  'degree': 1,\n",
       "  'gamma': 0.62325187337886645,\n",
       "  'kernel': 'polynomial'},\n",
       " 0.12330216555560318)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.grid_search import RandomizedSearchCV\n",
    "from scipy.stats import uniform as sp_rand\n",
    "krr = KernelRidge()\n",
    "params = {\n",
    "    'alpha':sp_rand(),\n",
    "    'gamma':sp_rand(),\n",
    "    'kernel':['linear','rbf','laplacian','polynomial','sigmoid'],\n",
    "    'degree':range(1,4),\n",
    "}\n",
    "model1 = RandomizedSearchCV(krr,params,cv=10,scoring='neg_mean_squared_error')\n",
    "model1.fit(x_new,y)\n",
    "'best parameters:',model1.best_params_,np.sqrt((-1)*model1.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "('best parameters:',\n",
    " {'alpha': 0.8097910445350851,\n",
    "  'degree': 1,\n",
    "  'gamma': 0.67999184729440021,\n",
    "  'kernel': 'polynomial'},\n",
    " 0.12363014896491431)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('best parameters:',\n",
       " {'criterion': 'mse',\n",
       "  'max_depth': 9,\n",
       "  'max_features': 0.5,\n",
       "  'min_samples_leaf': 2,\n",
       "  'n_estimators': 800,\n",
       "  'n_jobs': -1},\n",
       " 0.14397710758247814)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 这个模型训练会比较慢\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf = RandomForestRegressor()\n",
    "params = {\n",
    "    'n_estimators':[300,500,800,1000],\n",
    "    'criterion':['mse'],\n",
    "    'max_features':[0.5,'sqrt',0.3,0.8,'log2'],\n",
    "    'min_samples_leaf':[2,3,4],\n",
    "    'n_jobs':[-1],\n",
    "    'max_depth':[3,5,7,9]\n",
    "}\n",
    "model2 = RandomizedSearchCV(rf,params,cv=10,scoring='neg_mean_squared_error')\n",
    "model2.fit(x_new,y)\n",
    "'best parameters:',model2.best_params_,np.sqrt((-1)*model2.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "('best parameters:',\n",
    " {'criterion': 'mse',\n",
    "  'max_depth': 9,\n",
    "  'max_features': 0.8,\n",
    "  'min_samples_leaf': 2,\n",
    "  'n_estimators': 300,\n",
    "  'n_jobs': -1},\n",
    " 0.14337035947616186)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('best parameters:',\n",
       " {'learning_rate': 0.1,\n",
       "  'max_depth': 2,\n",
       "  'n_estimators': 500,\n",
       "  'reg_alpha': 0.4,\n",
       "  'reg_lambda': 0.3},\n",
       " 0.12090706644835847)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "xgb = XGBRegressor()\n",
    "params = {\n",
    "    'learning_rate':[0.1],\n",
    "    'max_depth':[2],\n",
    "    'n_estimators':[500],\n",
    "    'reg_alpha':[0.2,0.3,0.4,0.5,0.6],\n",
    "    'reg_lambda':[0.2,0.3,0.4,0.5,0.6,0.7]\n",
    "}\n",
    "model3 = RandomizedSearchCV(xgb,params,cv=10,scoring='neg_mean_squared_error')\n",
    "model3.fit(x_new,y)\n",
    "'best parameters:',model3.best_params_,np.sqrt((-1)*model3.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "('best parameters:',\n",
    " {'learning_rate': 0.1,\n",
    "  'max_depth': 2,\n",
    "  'n_estimators': 500,\n",
    "  'reg_alpha': 0.5,\n",
    "  'reg_lambda': 0.5},\n",
    " 0.12106369526470077)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''from sklearn.svm import SVR\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "sv = SVR(kernel='linear')\n",
    "model = GridSearchCV(sv, cv=10,\n",
    "                   param_grid={\"C\": [1e0, 1e-1, 1e-2, 1e-3],\n",
    "                               \"degree\":[2,3,4]},scoring='neg_mean_squared_error')\n",
    "model.fit(x_new,y)\n",
    "'best parameters:',model.best_params_,np.sqrt((-1)*model.best_score_)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"from sklearn.svm import SVR\\nfrom sklearn.grid_search import GridSearchCV\\nsv = SVR()\\n# Kernel 不要使用'precomputed'参数，因为precomputed这个核函数要求X为方阵\\nparams = {\\n    'C':[1e-2,1e-1,1],\\n    'epsilon':[0.01,0.1],\\n    'kernel':['rbf','poly','sigmoid'],\\n    'gamma':[1e-2,1e-1]\\n}\\nmodel = GridSearchCV(sv,params,scoring='neg_mean_squared_error')\\n# model = RandomizedSearchCV(sv,params,cv=10,scoring='neg_mean_squared_error')\\nmodel.fit(x_new,y)\\n'best parameters:',model.best_params_,np.sqrt((-1)*model.best_score_)\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''from sklearn.svm import SVR\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "sv = SVR()\n",
    "# Kernel 不要使用'precomputed'参数，因为precomputed这个核函数要求X为方阵\n",
    "params = {\n",
    "    'C':[1e-2,1e-1,1],\n",
    "    'epsilon':[0.01,0.1],\n",
    "    'kernel':['rbf','poly','sigmoid'],\n",
    "    'gamma':[1e-2,1e-1]\n",
    "}\n",
    "model = GridSearchCV(sv,params,scoring='neg_mean_squared_error')\n",
    "# model = RandomizedSearchCV(sv,params,cv=10,scoring='neg_mean_squared_error')\n",
    "model.fit(x_new,y)\n",
    "'best parameters:',model.best_params_,np.sqrt((-1)*model.best_score_)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('best parameters:',\n",
       " {'criterion': 'mse',\n",
       "  'learning_rate': 0.1,\n",
       "  'loss': 'huber',\n",
       "  'max_features': 'sqrt',\n",
       "  'n_estimators': 400},\n",
       " 0.12893263683942019)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "gb = GradientBoostingRegressor()\n",
    "params = {\n",
    "    'loss':['ls', 'lad', 'huber', 'quantile'],\n",
    "    'learning_rate':[1e-4,1e-3,1e-2,1e-1],\n",
    "    'n_estimators':[100,200,400],\n",
    "    'criterion':['mse'],\n",
    "    'max_features':['sqrt','log2']\n",
    "}\n",
    "model4 = GridSearchCV(gb,params,scoring='neg_mean_squared_error')\n",
    "model4.fit(x_new,y)\n",
    "'best parameters:',model4.best_params_,np.sqrt((-1)*model4.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "('best parameters:',\n",
    " {'criterion': 'mse',\n",
    "  'learning_rate': 0.1,\n",
    "  'loss': 'huber',\n",
    "  'max_features': 'sqrt',\n",
    "  'n_estimators': 400},\n",
    " 0.12741224009492616)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('best parameters:',\n",
       " {'alpha': 1e-05,\n",
       "  'fit_intercept': True,\n",
       "  'max_iter': 1000.0,\n",
       "  'normalize': False},\n",
       " 0.1233796262385489)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge,Lasso\n",
    "las = Lasso()\n",
    "params = {\n",
    "    'alpha':[1e-5,1e-4,1e-3,1e-2,1e-1,1],\n",
    "    'fit_intercept':[True,False],\n",
    "    'normalize':[True,False],\n",
    "    'max_iter':[1e1,1e2,1e3]\n",
    "}\n",
    "model5 = GridSearchCV(rid,params,scoring='neg_mean_squared_error')\n",
    "model5.fit(x_new,y)\n",
    "'best parameters:',model5.best_params_,np.sqrt((-1)*model5.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "('best parameters:',\n",
    " {'alpha': 1e-05,\n",
    "  'fit_intercept': True,\n",
    "  'max_iter': 1000.0,\n",
    "  'normalize': False},\n",
    " 0.1233796262385489)\n",
    " \n",
    " 其实这里使用LassoCV也行"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "得到模型：\n",
    "{\n",
    "    krr:12.363,\n",
    "    rf:14.337,\n",
    "    xgb:12.106,\n",
    "    gb:12.741,\n",
    "    las:12.338\n",
    "}\n",
    "姑且把这五个模型融合一下看看效果，虽然randomforest效果比较差，考虑到这个模型的口碑，还是尝试带入一下。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 表决融合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "This KernelRidge instance is not fitted yet. Call 'fit' with appropriate arguments before using this method.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFittedError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-3abe8b5d036b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmean_squared_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0myp\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mscore\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0mvoting_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_weights\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx_new\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-38-3abe8b5d036b>\u001b[0m in \u001b[0;36mvoting_model\u001b[1;34m(model_weights, x_new, y)\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0myp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmodel_weights\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[0myp_new\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_new\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m         \u001b[0myp\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0myp_new\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmean_squared_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0myp\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mH:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\kernel_ridge.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    181\u001b[0m             \u001b[0mReturns\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m         \"\"\"\n\u001b[1;32m--> 183\u001b[1;33m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"X_fit_\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"dual_coef_\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    184\u001b[0m         \u001b[0mK\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_kernel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mX_fit_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    185\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mK\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdual_coef_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mH:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_is_fitted\u001b[1;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[0;32m    766\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    767\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mall_or_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mattr\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mattributes\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 768\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'name'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    769\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    770\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotFittedError\u001b[0m: This KernelRidge instance is not fitted yet. Call 'fit' with appropriate arguments before using this method."
     ]
    }
   ],
   "source": [
    "model_weights = {\n",
    "    model1:0.2,\n",
    "    model2:0.1,\n",
    "    model3:0.25,\n",
    "    model4:0.2,\n",
    "    model5:0.25\n",
    "}\n",
    "def voting_model(model_weights,x_new,y):\n",
    "    yp = np.array([0 for i in range(len(y))]).reshape(-1,1)\n",
    "    for k,v in model_weights.items():\n",
    "        yp_new = k.predict(x_new)\n",
    "        yp += yp_new * v\n",
    "    score = np.sqrt(mean_squared_error(yp,y))\n",
    "    return score\n",
    "voting_model(model_weights,x_new,y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
